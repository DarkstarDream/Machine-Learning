{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d69877-458c-41f7-85aa-89603b82baf6",
   "metadata": {},
   "source": [
    "<a id='home'></a>\n",
    "### K Fold Cross validation\n",
    "\n",
    "### Model validation\n",
    "We always don't have enough data for creating a ml model even in that case we have to split it for training and validation/testing of a model, because if we not validate our model then we won't be able to know its performance. And also we can't use the same data for both training and validation as it is will not give the good estimation of its performance on unseen data.\n",
    "\n",
    "### Problem with traditional validation method\n",
    "In tradational approach, we split our data in ratio of 70:30 or 80:20 etc and pass the major chunk of data for training and rest for validation/testing, this method is know as `Holdout method`. But the problem with this approach is that the model is not fully able to understand the pattern of the data and if the dataset is not large enough then model gets underfitted. <br>\n",
    "> <img src=\"https://d1m75rqqgidzqn.cloudfront.net/wp-data/2020/07/15185319/blogs-15-7-2020-02-1024x565.jpg\" width=\"500\">\n",
    "\n",
    "Holdout method is similar of teaching a kid, from first 7 chapter or 7 random chapter of a book and then testing his learning with rest of chapters of that book.\n",
    "\n",
    "### How cross validation solves the issue\n",
    "Cross validation is one of the most popular yet simplest data sampling techniques, the basic idea of cross validation is to utilize the whole dataset for training and validation. Because of this approach, model is able to fully utilize the given dataset and understand the complete pattern of data and it also helps it overcome the underfitting issue. Cross validation is also used for finding the best performing model(different algos) or for finding best parameter of a particular model.\n",
    "\n",
    "\n",
    "### Why do we need cross validation\n",
    "As we always don't have enough data to train our model, removing a part of it for validation poses a problem of underfitting. By reducing the training data, we risk losing important patterns/ trends in data set, which in turn increases error induced by bias. So, what we require is a method that provides ample data for training the model and also leaves ample data for validation. K Fold cross validation does exactly that.\n",
    "\n",
    "### Types of Cross Validation\n",
    "1. [KFold Cross Validation](#kfold)\n",
    "2. [Stratified KFold Cross Validation](#scv)\n",
    "3. [Leave-P-Out Cross Validation](#lcv)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf8949-d0ca-4c35-8028-f726730ceba5",
   "metadata": {},
   "source": [
    "## Building different validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4559732d-12ae-4d5d-a698-d0bec322b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.datasets import load_wine # <-- dataset we will be using\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81da0122-8b0e-448c-bc7c-e1ffc5f94861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]]\n",
      "----------------------------------------\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# dataset \n",
    "features = load_wine().data\n",
    "label = load_wine().target\n",
    "\n",
    "print(features[:5])\n",
    "print('--'*20)\n",
    "print(label[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163c907d-73fd-42f8-8b69-684f51a59a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13) (178,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3a188-9a54-40c4-8115-e13995dde1a1",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "### Holdout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a488c872-c6cf-4508-8094-f92713c784f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13) (36, 13) (142,) (36,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=41)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a789db-31cd-4c41-b4ea-216dc490382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score\n",
      " 1.0 \n",
      "Testing Score\n",
      " 0.9722222222222222\n",
      "-------------------- \n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.92      0.96        12\n",
      "           2       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and validation\n",
    "model = RandomForestClassifier().fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print('Training Score\\n', model.score(x_train, y_train), '\\nTesting Score\\n',model.score(x_test, y_test))\n",
    "print('-'*20, '\\nClassification Report\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb59e90-2d30-409f-8dc0-08875749ba2b",
   "metadata": {},
   "source": [
    "> Accuracy of the model is affected by the data it is trained on, and data on which model will be trained on is dependent on the how we split it. Here we are splitting our data with `Holdout method`, in which some portion of data are never used for training our model (which is used for validation) because of which our model didn't get the opportuinty to learn the complete pattern of the data.\n",
    "\n",
    "> For example if we change the `random_state` in `train_test_split` function (responsible randomly splitting the data) our model will give different accuracy, though there may or may not be huge difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20fbba8d-7a27-4d16-9b18-52cc979aac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13) (36, 13) (142,) (36,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=56)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7bcb10-d092-4b78-b341-96e3c5fa2103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score\n",
      " 1.0 \n",
      "Testing Score\n",
      " 0.9444444444444444\n",
      "-------------------- \n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.83      0.91        12\n",
      "           2       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier().fit(x_train, y_train)\n",
    "\n",
    "# Test report \n",
    "y_pred = model.predict(x_test)\n",
    "print('Training Score\\n', model.score(x_train, y_train), '\\nTesting Score\\n',model.score(x_test, y_test))\n",
    "print('-'*20, '\\nClassification Report\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550a343-2af2-49dd-ade3-3f72ca13d59e",
   "metadata": {},
   "source": [
    "> As you can see, we got better accuracy in from our previous model, just from changing value of random state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073fdf49-7a83-4ecc-a34a-d6ece973ca8e",
   "metadata": {},
   "source": [
    "<a id='kfold'></a>\n",
    "### 1. K Fold\n",
    "It first divides the whole data into `K` number of subset (K is decided by user) for training and validation of a model. Then the model is trained for `K` times with `K-1` different subset of data and validated on left 1 subset of the data. Basically it follows `Holdout method` for K times with different sample of training and testing data each time. After training and validating the model K times we get K different accuracy score of model, so we average them out to get the overall effectiveness of our model\n",
    "> <img src=\"https://zitaoshen.rbind.io/project/machine_learning/machine-learning-101-cross-vaildation/featured.png\" width=\"600\">\n",
    "\n",
    "**[▲ Go To Top](#home)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6202d227-f9bf-4111-bc62-3c56fce1e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, shuffle=True) # <-- here n_splits parameter is the value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56e5e69-924a-4240-aa80-846dc97ce2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 5 6 7 8 9] [0 4]\n",
      "[0 1 3 4 5 7 8 9] [2 6]\n",
      "[0 2 3 4 6 7 8 9] [1 5]\n",
      "[0 1 2 4 5 6 7 9] [3 8]\n",
      "[0 1 2 3 4 5 6 8] [7 9]\n"
     ]
    }
   ],
   "source": [
    "# how KFold works (demonstration)\n",
    "for train, test in cv.split(range(10)):\n",
    "     print(train, test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf1008-7528-4299-b4a5-821dd8cf781f",
   "metadata": {},
   "source": [
    "> In above metric you can easily see that we have 5 (value of K) different train test arrays each time. Similary if we apply KFold on our data it will create 5 different splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c8402d-2d4a-4583-9494-e5d56c0736db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 4 5 6 8 9] [2 7]\n",
      "[0 1 2 3 5 6 7 9] [4 8]\n",
      "[0 2 3 4 6 7 8 9] [1 5]\n",
      "[0 1 2 4 5 6 7 8] [3 9]\n",
      "[1 2 3 4 5 7 8 9] [0 6]\n"
     ]
    }
   ],
   "source": [
    "# cv.split(data) <-- it returns the index not actual values -(remember that)\n",
    "for train, test in cv.split(range(100, 110)):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4439cbe2-c00f-4a1f-bea8-86d701630c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n",
      "1.0\n",
      "0.9722222222222222\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# splitting data with KFold\n",
    "scores = []\n",
    "for train_index, test_index in cv.split(features):\n",
    "    x_train, x_test, y_train, y_test = features[train_index], features[test_index], label[train_index], label[test_index]\n",
    "    model = RandomForestClassifier().fit(x_train, y_train)\n",
    "    \n",
    "    # for simplicity we will only get training score\n",
    "    test_score = model.score(x_test, y_test)\n",
    "    scores.append(test_score)\n",
    "    print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a82380-30ea-44d5-9e1c-d9ffffea3b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# now to get the model's overall performance we can take average of all tried model\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea73655-a738-4f37-902e-1a8a6e37a34f",
   "metadata": {},
   "source": [
    "> So this is estimate of best performance we can get from using Random Forest on this data. We can try different model with cross validation to find the best model\n",
    "\n",
    "> There's another way to use the KFold cross validation, which is easier and shorter than this to implement. The method can be used with a method called `cross_val_score`, so lets see how we can implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80f9b0e5-830f-40e8-858e-719c0f2affaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94444444 0.94444444 0.91666667 1.         0.97142857]\n",
      "0.9775280898876404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(RandomForestClassifier(), features, label, cv=5, scoring='accuracy')\n",
    "print(score)\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4213202-a62f-4b77-b95b-a47efa43001f",
   "metadata": {},
   "source": [
    "<a id='scv'></a>\n",
    "### 2. StratifiedKFold\n",
    "In some cases, there may be a large imbalance in the response aka target variables. For example, in dataset concerning price of houses, there might be large number of houses having high price. Or in case of classification, there might be several times more negative samples than positive samples. For such problems, a slight variation in the K Fold cross validation technique is made, such that each fold contains approximately the same percentage of samples of each target class as the complete set, or in case of prediction problems, the mean response value is approximately equal in all the folds. This variation is also known as Stratified K Fold.\n",
    "\n",
    "**[▲ Go To Top](#home)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b48d406b-6f83-4315-852f-d93e022980d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "s_cv = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "481764ed-1c97-4674-93bf-2849deeef023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9142857142857143\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "# here feature and label is of np array type\n",
    "for train_index, test_index in s_cv.split(features, label):\n",
    "    x_train, x_test, y_train, y_test = features[train_index], features[test_index], label[train_index], label[test_index]\n",
    "    model = RandomForestClassifier().fit(x_train, y_train)\n",
    "    \n",
    "    # for simplicity we will only get training score\n",
    "    test_score = model.score(x_test, y_test)scv = StratifiedKFold(n_splits=5, random_state=49, shuffle=True)\n",
    "scv_score = []\n",
    "    scores.append(test_score)\n",
    "    print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86ce06cd-83f3-4a03-9d97-b935d0ce4129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9828571428571429\n"
     ]
    }
   ],
   "source": [
    "# now to get the model's overall performance we can take average of all tried model\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f027f51-e5f7-4261-a827-8f2b9a091edf",
   "metadata": {},
   "source": [
    "<a id='lcv'></a>\n",
    "### Leave-P-Out Cross Validation\n",
    "This approach leaves p data points out of training data, i.e. if there are n data points in the original sample then, n-p samples are used to train the model and p points are used as the validation set. This is repeated for all combinations in which original sample can be separated this way, and then the error is averaged for all trials, to give overall effectiveness.\n",
    "This method is exhaustive in the sense that it needs to train and validate the model for all possible combinations, and for moderately large p, it can become **computationally infeasible**.\n",
    "\n",
    "**[▲ Go To Top](#home)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11c7c4c5-52e5-44e6-a9cc-df13021c0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "l_cv = LeavePOut(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4982d548-3a12-458c-9c31-050c8edbee36",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for train_index, test_index in l_cv.split(features, label):\n",
    "    x_train, x_test, y_train, y_test = features[train_index], features[test_index], label[train_index], label[test_index]\n",
    "    model = RandomForestClassifier().fit(x_train, y_train)\n",
    "    \n",
    "    # for simplicity we will only get training score\n",
    "    test_score = model.score(x_test, y_test)\n",
    "    scores.append(test_score)\n",
    "    print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ca3f6ac-fa33-4f87-9989-529cbfa71344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775280898876404\n"
     ]
    }
   ],
   "source": [
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "064c26e9-0d69-4346-996f-cccb8ee2ec7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57d64985-fc77-4837-a74a-8a61841695cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d17d5f-a0ef-4069-ad81-cbd969b9a788",
   "metadata": {},
   "source": [
    "Here you can see we trained 177 model with 177 possible combinations of data, leaving one for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2fbd6-3579-47f6-bf39-9c43d824cf55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
